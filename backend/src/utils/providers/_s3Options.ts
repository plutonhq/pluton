const s3Options = [
	{
		label: 'Server-side Encryption',
		value: 'server_side_encryption',
		fieldType: 'string',
		required: false,
		default: '',
		description: 'The server-side encryption algorithm used when storing this object in S3.',
		command: '--s3-server-side-encryption',
	},
	{
		label: 'SSE KMS ID',
		value: 'sse_kms_key_id',
		fieldType: 'string',
		required: false,
		default: '',
		description: 'If using KMS ID you must provide the ARN of Key.',
		command: '--s3-sse-kms-key-id',
	},
	{
		label: 'Storage Class',
		value: 'storage_class',
		fieldType: 'string',
		required: false,
		default: '',
		description: 'The storage class to use when storing new objects in S3.',
		command: '--s3-storage-class',
	},
	{
		label: 'Bucket ACL',
		value: 'bucket_acl',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'Canned ACL used when creating buckets. For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl',
		command: '--s3-bucket-acl',
	},
	{
		label: 'Requester pays',
		value: 'requester_pays',
		fieldType: 'bool',
		required: false,
		default: false,
		description: 'Enables requester pays option when interacting with S3 bucket.',
		command: '--s3-requester-pays',
	},
	{
		label: 'Use SSE-C Algorithm',
		value: 'sse_customer_algorithm',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'If using SSE-C, the server-side encryption algorithm used when storing this object in S3.',
		command: '--s3-sse-customer-algorithm',
	},
	{
		label: 'SSE-C Key',
		value: 'sse_customer_key',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'To use SSE-C you may provide the secret encryption key used to encrypt/decrypt your data. Alternatively you can provide --sse-customer-key-base64.',
		command: '--s3-sse-customer-key',
	},
	{
		label: 'SSE-C Key (Base64 Encoded)',
		value: 'sse_customer_key_base64',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'If using SSE-C you must provide the secret encryption key encoded in base64 format to encrypt/decrypt your data. Alternatively you can provide --sse-customer-key.',
		command: '--s3-sse-customer-key-base64',
	},
	{
		label: 'SSE-C Key (MD5 checksum)',
		value: 'sse_customer_key_md5',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'If using SSE-C you may provide the secret encryption key MD5 checksum (optional). If you leave it blank, this is calculated automatically from the sse_customer_key provided.',
		command: '--s3-sse-customer-key-md5',
	},
	{
		label: 'Upload Cutoff',
		value: 'upload_cutoff',
		fieldType: 'sizesuffix',
		required: false,
		default: '200mi',
		description:
			'Cutoff for switching to chunked upload. Any files larger than this will be uploaded in chunks of chunk_size. The minimum is 0 and the maximum is 5 GiB.',
		command: '--s3-upload-cutoff',
	},
	{
		label: 'Chunk Size',
		value: 'chunk_size',
		fieldType: 'sizesuffix',
		required: false,
		default: '5mi',
		description:
			'Chunk size to use for uploading. When uploading files larger than upload_cutoff or files with unknown size (e.g. from "rclone rcat" or uploaded with "rclone mount" or google photos or google docs) they will be uploaded as multipart uploads using this chunk size.',
		command: '--s3-chunk-size',
	},
	{
		label: 'Max Upload Parts',
		value: 'max_upload_parts',
		fieldType: 'int',
		required: false,
		default: '10000',
		description:
			'Maximum number of parts in a multipart upload. This option defines the maximum number of multipart chunks to use when doing a multipart upload.',
		command: '--s3-max-upload-parts',
	},
	{
		label: 'Copy Cutoff',
		value: 'copy_cutoff',
		fieldType: 'sizesuffix',
		required: false,
		default: '4.656gi',
		description:
			'Cutoff for switching to multipart copy. Any files larger than this that need to be server-side copied will be copied in chunks of this size.',
		command: '--s3-copy-cutoff',
	},
	{
		label: 'Disable Checksum',
		value: 'disable_checksum',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			"Don't store MD5 checksum with object metadata. Normally rclone will calculate the MD5 checksum of the input before uploading it so it can add it to metadata on the object. This is great for data integrity checking but can cause long delays for large files to start uploading.",
		command: '--s3-disable-checksum',
	},
	{
		label: 'Shared Credentials File',
		value: 'shared_credentials_file',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'Path to the shared credentials file. If env_auth = true then rclone can use a shared credentials file.',
		command: '--s3-shared-credentials-file',
	},
	{
		label: 'Profile',
		value: 'profile',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'Profile to use in the shared credentials file. If env_auth = true then rclone can use a shared credentials file. This variable controls which profile is used in that file.',
		command: '--s3-profile',
	},
	{
		label: 'Session Token',
		value: 'session_token',
		fieldType: 'string',
		required: false,
		default: '',
		description: 'An AWS session token.',
		command: '--s3-session-token',
	},
	{
		label: 'Upload Concurrency',
		value: 'upload_concurrency',
		fieldType: 'int',
		required: false,
		default: '4',
		description:
			'Concurrency for multipart uploads and copies. This is the number of chunks of the same file that are uploaded concurrently for multipart uploads and copies.',
		command: '--s3-upload-concurrency',
	},
	{
		label: 'Force Path Style',
		value: 'force_path_style',
		fieldType: 'bool',
		required: false,
		default: true,
		description:
			'If true use path style access if false use virtual hosted style. If this is true (the default) then rclone will use path style access, if false then rclone will use virtual path style. See the AWS S3 docs for more info.',
		command: '--s3-force-path-style',
	},
	{
		label: 'V2 Authentication',
		value: 'v2_auth',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'If true use v2 authentication. If this is false (the default) then rclone will use v4 authentication. If it is set then rclone will use v2 authentication.',
		command: '--s3-v2-auth',
	},
	{
		label: 'Use Dual-Stack endpoint',
		value: 'use_dual_stack',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'If true use AWS S3 dual-stack endpoint (IPv6 support). See AWS Docs on Dualstack Endpoints',
		command: '--s3-use-dual-stack',
	},
	{
		label: 'Use Accelerated endpoint',
		value: 'use_accelerate_endpoint',
		fieldType: 'bool',
		required: false,
		default: false,
		description: 'If true use the AWS S3 accelerated endpoint. See: AWS S3 Transfer acceleration',
		command: '--s3-use-accelerate-endpoint',
	},
	{
		label: 'Leave Parts On Error',
		value: 'leave_parts_on_error',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery. It should be set to true for resuming uploads across different sessions.',
		command: '--s3-leave-parts-on-error',
	},
	{
		label: 'List Chunk',
		value: 'list_chunk',
		fieldType: 'int',
		required: false,
		default: '1000',
		description:
			'Size of listing chunk (response list for each ListObject S3 request). This option is also known as "MaxKeys", "max-items", or "page-size" from the AWS S3 specification. Most services truncate the response list to 1000 objects even if requested more than that. In AWS S3 this is a global maximum and cannot be changed, see AWS S3. In Ceph, this can be increased with the "rgw list buckets max chunk" option.',
		command: '--s3-list-chunk',
	},
	{
		label: 'List Version',
		value: 'list_version',
		fieldType: 'int',
		required: false,
		default: '0',
		description:
			'Version of ListObjects to use: 1,2 or 0 for auto. When S3 originally launched it only provided the ListObjects call to enumerate objects in a bucket.',
		command: '--s3-list-version',
	},
	{
		label: 'List URL Encode',
		value: 'list_url_encode',
		fieldType: 'tristate',
		required: false,
		default: 'unset',
		description:
			"Whether to url encode listings: true/false/unset Some providers support URL encoding listings and where this is available this is more reliable when using control characters in file names. If this is set to unset (the default) then rclone will choose according to the provider setting what to apply, but you can override rclone's choice here.",
		command: '--s3-list-url-encode',
	},
	{
		label: 'No Check Bucket',
		value: 'no_check_bucket',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			"If set, don't attempt to check the bucket exists or create it. This can be useful when trying to minimise the number of transactions rclone does if you know the bucket exists already.",
		command: '--s3-no-check-bucket',
	},
	{
		label: 'No Head',
		value: 'no_head',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			"If set, don't HEAD uploaded objects to check integrity. This can be useful when trying to minimise the number of transactions rclone does.",
		command: '--s3-no-head',
	},
	{
		label: 'No Head Object',
		value: 'no_head_object',
		fieldType: 'bool',
		required: false,
		default: false,
		description: 'If set, do not do HEAD before GET when getting objects.',
		command: '--s3-no-head-object',
	},
	{
		label: 'Encoding',
		value: 'encoding',
		fieldType: 'encoding',
		required: false,
		default: 'slash,invalidutf8,dot',
		description:
			'The encoding for the backend. See the encoding section in the overview for more info.',
		command: '--s3-encoding',
	},
	{
		label: 'Memory Pool Flush Time',
		value: 'memory_pool_flush_time',
		fieldType: 'duration',
		required: false,
		default: '1m0s',
		description: 'How often internal memory buffer pools will be flushed. (no longer used)',
		command: '--s3-memory-pool-flush-time',
	},
	{
		label: 'Memory Pool Use MMAP',
		value: 'memory_pool_use_mmap',
		fieldType: 'bool',
		required: false,
		default: false,
		description: 'Whether to use mmap buffers in internal memory pool. (no longer used)',
		command: '--s3-memory-pool-use-mmap',
	},
	{
		label: 'Disable HTTP2',
		value: 'disable_http2',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'Disable usage of http2 for S3 backends. There is currently an unsolved issue with the s3 (specifically minio) backend and HTTP/2.  HTTP/2 is enabled by default for the s3 backend but can be disabled here.  When the issue is solved this flag will be removed.',
		command: '--s3-disable-http2',
	},
	{
		label: 'Download URL',
		value: 'download_url',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'Custom endpoint for downloads. This is usually set to a CloudFront CDN URL as AWS S3 offers cheaper egress for data downloaded through the CloudFront network.',
		command: '--s3-download-url',
	},
	{
		label: 'Directory Markers',
		value: 'directory_markers',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'Upload an empty object with a trailing slash when a new directory is created Empty folders are unsupported for bucket based storages, this option creates an empty object ending with "/", to persist the folder.',
		command: '--s3-directory-markers',
	},
	{
		label: 'Use Multipart ETag',
		value: 'use_multipart_etag',
		fieldType: 'tristate',
		required: false,
		default: 'unset',
		description:
			'Whether to use ETag in multipart uploads for verification This should be true, false or left unset to use the default for the provider.',
		command: '--s3-use-multipart-etag',
	},
	{
		label: 'Use Unsigned Payload',
		value: 'use_unsigned_payload',
		fieldType: 'tristate',
		required: false,
		default: 'unset',
		description:
			"Whether to use an unsigned payload in PutObject Rclone has to avoid the AWS SDK seeking the body when calling PutObject. The AWS provider can add checksums in the trailer to avoid seeking but other providers can't.",
		command: '--s3-use-unsigned-payload',
	},
	{
		label: 'Use Presigned Request',
		value: 'use_presigned_request',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'Whether to use a presigned request or PutObject for single part uploads If this is false rclone will use PutObject from the AWS SDK to upload an object.',
		command: '--s3-use-presigned-request',
	},
	{
		label: 'Include Versions',
		value: 'versions',
		fieldType: 'bool',
		required: false,
		default: false,
		description: 'Include old versions in directory listings.',
		command: '--s3-versions',
	},
	{
		label: 'Version At',
		value: 'version_at',
		fieldType: 'time',
		required: false,
		default: 'off',
		description:
			'Show file versions as they were at the specified time. The parameter should be a date, "2006-01-02", datetime "2006-01-02 15:04:05" or a duration for that long ago, eg "100d" or "1h".',
		command: '--s3-version-at',
	},
	{
		label: 'Show deleted file markers',
		value: 'version_deleted',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'Show deleted file markers when using versions. This shows deleted file markers in the listing when using versions. These will appear as 0 size files. The only operation which can be performed on them is deletion.',
		command: '--s3-version-deleted',
	},
	{
		label: 'Decompress',
		value: 'decompress',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'If set this will decompress gzip encoded objects. It is possible to upload objects to S3 with "Content-Encoding: gzip" set. Normally rclone will download these files as compressed objects.',
		command: '--s3-decompress',
	},
	{
		label: 'Might GZIP',
		value: 'might_gzip',
		fieldType: 'tristate',
		required: false,
		default: 'unset',
		description:
			"Set this if the backend might gzip objects. Normally providers will not alter objects when they are downloaded. If an object was not uploaded with Content-Encoding: gzip then it won't be set on download.",
		command: '--s3-might-gzip',
	},
	{
		label: 'Use Accept Encoding GZIP',
		value: 'use_accept_encoding_gzip',
		fieldType: 'tristate',
		required: false,
		default: 'unset',
		description:
			'Whether to send Accept-Encoding: gzip header. By default, rclone will append Accept-Encoding: gzip to the request to download compressed objects whenever possible.',
		command: '--s3-use-accept-encoding-gzip',
	},
	{
		label: 'No System Metadata',
		value: 'no_system_metadata',
		fieldType: 'bool',
		required: false,
		default: false,
		description: 'Suppress setting and reading of system metadata',
		command: '--s3-no-system-metadata',
	},
	{
		label: 'STS Endpoint',
		value: 'sts_endpoint',
		fieldType: 'string',
		required: false,
		default: '',
		description:
			'Endpoint for STS (deprecated). Leave blank if using AWS to use the default endpoint for the region.',
		command: '--s3-sts-endpoint',
	},
	{
		label: 'Use Already Exists',
		value: 'use_already_exists',
		fieldType: 'tristate',
		required: false,
		default: 'unset',
		description:
			'Set if rclone should report BucketAlreadyExists errors on bucket creation. At some point during the evolution of the s3 protocol, AWS started returning an AlreadyOwnedByYou error when attempting to create a bucket that the user already owned, rather than a BucketAlreadyExists error.',
		command: '--s3-use-already-exists',
	},
	{
		label: 'Use Multipart Uploads',
		value: 'use_multipart_uploads',
		fieldType: 'tristate',
		required: false,
		default: 'unset',
		description:
			"Set if rclone should use multipart uploads. You can change this if you want to disable the use of multipart uploads. This shouldn't be necessary in normal operation.",
		command: '--s3-use-multipart-uploads',
	},
	{
		label: 'Directory Bucket',
		value: 'directory_bucket',
		fieldType: 'bool',
		required: false,
		default: false,
		description:
			'Set to use AWS Directory Buckets If you are using an AWS Directory Bucket then set this flag.',
		command: '--s3-directory-bucket',
	},
	{
		label: 'SDK Log Mode',
		value: 'sdk_log_mode',
		fieldType: 'bits',
		required: false,
		default: 'off',
		description:
			'Set to debug the SDK This can be set to a comma separated list of the following functions:',
		command: '--s3-sdk-log-mode',
	},
	{
		label: 'Description',
		value: 'description',
		fieldType: 'string',
		required: false,
		default: '',
		description: 'Description of the Storage.',
		command: '--s3-description',
	},
];

export default s3Options;
